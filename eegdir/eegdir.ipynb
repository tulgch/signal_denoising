{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 SNR Levels: dict_keys([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
      "🔹 Clean EEG Shape: (3400, 512)\n",
      "🔹 SNR Level -7: Shape = (3400, 512)\n",
      "🔹 SNR Level -6: Shape = (3400, 512)\n",
      "🔹 SNR Level -5: Shape = (3400, 512)\n",
      "🔹 SNR Level -4: Shape = (3400, 512)\n",
      "🔹 SNR Level -3: Shape = (3400, 512)\n",
      "🔹 SNR Level -2: Shape = (3400, 512)\n",
      "🔹 SNR Level -1: Shape = (3400, 512)\n",
      "🔹 SNR Level 0: Shape = (3400, 512)\n",
      "🔹 SNR Level 1: Shape = (3400, 512)\n",
      "🔹 SNR Level 2: Shape = (3400, 512)\n",
      "\n",
      "✅ Dataset successfully loaded and converted to tensors!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Define local dataset paths\n",
    "synthetic_eeg_eog_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/Linear_synthetic_eeg_eog.npy\"\n",
    "clean_eeg_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/EEG_all_epochs.npy\"\n",
    "\n",
    "# Load dataset\n",
    "synthetic_eeg_eog = np.load(synthetic_eeg_eog_path, allow_pickle=True).item()  # Dictionary of SNR levels\n",
    "clean_eeg = np.load(clean_eeg_path)  # Ground truth EEG\n",
    "\n",
    "# Check dataset properties\n",
    "print(\"🔹 SNR Levels:\", synthetic_eeg_eog.keys())\n",
    "print(\"🔹 Clean EEG Shape:\", clean_eeg.shape)\n",
    "\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    print(f\"🔹 SNR Level {snr}: Shape = {synthetic_eeg_eog[snr].shape}\")\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "synthetic_eeg_eog_tensors = {snr: torch.tensor(synthetic_eeg_eog[snr], dtype=torch.float32) for snr in synthetic_eeg_eog.keys()}\n",
    "clean_eeg_tensor = torch.tensor(clean_eeg, dtype=torch.float32)\n",
    "\n",
    "print(\"\\n✅ Dataset successfully loaded and converted to tensors!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Training Data Shape: torch.Size([27200, 512])\n",
      "✅ Testing Data Shape: torch.Size([6800, 512])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Store train/test data separately\n",
    "X_train_list, X_test_list = [], []\n",
    "y_train_list, y_test_list = [], []\n",
    "\n",
    "# Loop through each SNR level and split data\n",
    "for snr in synthetic_eeg_eog_tensors.keys():\n",
    "    contaminated_signals = synthetic_eeg_eog_tensors[snr]  # Noisy EEG for this SNR level\n",
    "    clean_signals = clean_eeg_tensor  # Corresponding clean EEG\n",
    "\n",
    "    # Ensure both datasets match in order\n",
    "    assert contaminated_signals.shape == clean_signals.shape, f\"Shape mismatch at SNR {snr}\"\n",
    "\n",
    "    # Split 80% training, 20% testing\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        contaminated_signals, clean_signals, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Append to lists\n",
    "    X_train_list.append(X_train)\n",
    "    X_test_list.append(X_test)\n",
    "    y_train_list.append(y_train)\n",
    "    y_test_list.append(y_test)\n",
    "\n",
    "# Stack all SNR-level data\n",
    "X_train_final = torch.cat(X_train_list, dim=0)\n",
    "X_test_final = torch.cat(X_test_list, dim=0)\n",
    "y_train_final = torch.cat(y_train_list, dim=0)\n",
    "y_test_final = torch.cat(y_test_list, dim=0)\n",
    "\n",
    "# Print shapes\n",
    "print(\"✅ Training Data Shape:\", X_train_final.shape)\n",
    "print(\"✅ Testing Data Shape:\", X_test_final.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class DiRBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Implements a single DiR Block with:\n",
    "    - Pre-Norm (Layer Normalization)\n",
    "    - Multi-Scale Retention (MSR)\n",
    "    - Residual Connection\n",
    "    - Feedforward Network (FFN)\n",
    "    \"\"\"\n",
    "    def __init__(self, embed_dim=512, num_heads=8, retention_size=512):\n",
    "        super(DiRBlock, self).__init__()\n",
    "\n",
    "        # Pre-Norm before retention mechanism\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Multi-Scale Retention (MSR)\n",
    "        self.retention = nn.MultiheadAttention(embed_dim, num_heads, batch_first=True)\n",
    "\n",
    "        # Residual Connection\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "\n",
    "        # Feedforward Network (FFN)\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(embed_dim, retention_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(retention_size, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass for the DiR block.\n",
    "        \"\"\"\n",
    "        # Pre-Normalization & Multi-Scale Retention\n",
    "        residual = x\n",
    "        x = self.norm1(x)\n",
    "        x, _ = self.retention(x, x, x)\n",
    "        x = residual + x  # Residual Connection\n",
    "\n",
    "        # Pre-Normalization & Feedforward Network (FFN)\n",
    "        residual = x\n",
    "        x = self.norm2(x)\n",
    "        x = self.ffn(x)\n",
    "        \n",
    "        return residual + x  # Final Residual Connection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEGDiR(\n",
      "  (embedding): Linear(in_features=512, out_features=512, bias=True)\n",
      "  (dir_blocks): Sequential(\n",
      "    (0): DiRBlock(\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (retention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (1): DiRBlock(\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (retention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (2): DiRBlock(\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (retention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "    (3): DiRBlock(\n",
      "      (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (retention): MultiheadAttention(\n",
      "        (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "      (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      (ffn): Sequential(\n",
      "        (0): Linear(in_features=512, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (output_layer): Linear(in_features=512, out_features=512, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class EEGDiR(nn.Module):\n",
    "    \"\"\"\n",
    "    EEGDiR Model for EEG Denoising using the Retentive Network.\n",
    "    \"\"\"\n",
    "    def __init__(self, seq_len=512, embed_dim=512, num_blocks=4, num_heads=8):\n",
    "        super(EEGDiR, self).__init__()\n",
    "\n",
    "        # Signal Embedding: Convert EEG (1D 512) → (Hidden dim 512)\n",
    "        self.embedding = nn.Linear(seq_len, embed_dim)\n",
    "\n",
    "        # Stacked Retentive Blocks (DiR Blocks)\n",
    "        self.dir_blocks = nn.Sequential(*[DiRBlock(embed_dim, num_heads) for _ in range(num_blocks)])\n",
    "\n",
    "        # Output Projection: Convert back to original EEG dimension\n",
    "        self.output_layer = nn.Linear(embed_dim, seq_len)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Forward pass through EEGDiR.\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)  # Project input EEG to hidden dimension\n",
    "        x = self.dir_blocks(x)  # Pass through DiR blocks\n",
    "        x = self.output_layer(x)  # Convert back to original EEG format\n",
    "        return x\n",
    "\n",
    "# Initialize the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = EEGDiR().to(device)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model Output Shape: torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "sample_input = torch.randn(1, 512).to(device)  # Simulated EEG signal\n",
    "output = model(sample_input)\n",
    "print(\"✅ Model Output Shape:\", output.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# Define loss function (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Define optimizer (AdamW for stable training)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Early Stopping Parameters\n",
    "patience = 10  # Stop training if validation loss does not improve for 10 epochs\n",
    "best_val_loss = float('inf')\n",
    "epochs_no_improve = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000] - Train Loss: 34460.322193 - Val Loss: 34622.608259 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [2/1000] - Train Loss: 32870.860315 - Val Loss: 33205.401507 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [3/1000] - Train Loss: 31483.047020 - Val Loss: 32010.715960 - Time: 0.72s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [4/1000] - Train Loss: 30310.525969 - Val Loss: 30954.676060 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [5/1000] - Train Loss: 29243.293186 - Val Loss: 30030.370536 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [6/1000] - Train Loss: 28287.648582 - Val Loss: 29203.493304 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [7/1000] - Train Loss: 27385.288773 - Val Loss: 28448.164900 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [8/1000] - Train Loss: 26603.697772 - Val Loss: 27755.542690 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [9/1000] - Train Loss: 25818.776693 - Val Loss: 27093.538225 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [10/1000] - Train Loss: 25106.452474 - Val Loss: 26503.854353 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [11/1000] - Train Loss: 24411.823351 - Val Loss: 25915.045480 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [12/1000] - Train Loss: 23762.842231 - Val Loss: 25384.699219 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [13/1000] - Train Loss: 23114.628979 - Val Loss: 24880.385603 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [14/1000] - Train Loss: 22534.314308 - Val Loss: 24388.679129 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [15/1000] - Train Loss: 21992.086516 - Val Loss: 23939.971261 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [16/1000] - Train Loss: 21448.208695 - Val Loss: 23562.085658 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [17/1000] - Train Loss: 20951.173105 - Val Loss: 23160.736886 - Time: 0.70s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [18/1000] - Train Loss: 20484.829065 - Val Loss: 22777.257254 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [19/1000] - Train Loss: 20029.468244 - Val Loss: 22426.701172 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [20/1000] - Train Loss: 19601.486039 - Val Loss: 22096.209542 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [21/1000] - Train Loss: 19232.825521 - Val Loss: 21850.167132 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [22/1000] - Train Loss: 18862.956163 - Val Loss: 21548.428292 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [23/1000] - Train Loss: 18506.610243 - Val Loss: 21293.989397 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [24/1000] - Train Loss: 18150.073568 - Val Loss: 21062.917132 - Time: 0.68s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [25/1000] - Train Loss: 17852.862341 - Val Loss: 20786.024554 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [26/1000] - Train Loss: 17565.962529 - Val Loss: 20568.746652 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [27/1000] - Train Loss: 17275.379774 - Val Loss: 20350.244699 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [28/1000] - Train Loss: 17005.770978 - Val Loss: 20164.558873 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [29/1000] - Train Loss: 16712.030707 - Val Loss: 19985.814174 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [30/1000] - Train Loss: 16487.899703 - Val Loss: 19789.994699 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [31/1000] - Train Loss: 16248.963505 - Val Loss: 19662.020926 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [32/1000] - Train Loss: 16020.295718 - Val Loss: 19434.634487 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [33/1000] - Train Loss: 15801.759766 - Val Loss: 19294.638393 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [34/1000] - Train Loss: 15595.603009 - Val Loss: 19146.592215 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [35/1000] - Train Loss: 15388.777959 - Val Loss: 19023.274833 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [36/1000] - Train Loss: 15192.139648 - Val Loss: 18898.306362 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [37/1000] - Train Loss: 15000.397859 - Val Loss: 18756.426618 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [38/1000] - Train Loss: 14828.513672 - Val Loss: 18621.555106 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [39/1000] - Train Loss: 14644.957935 - Val Loss: 18514.724330 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [40/1000] - Train Loss: 14476.095920 - Val Loss: 18378.704660 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [41/1000] - Train Loss: 14312.979203 - Val Loss: 18261.142299 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [42/1000] - Train Loss: 14155.086444 - Val Loss: 18151.272321 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [43/1000] - Train Loss: 14007.739113 - Val Loss: 18043.389509 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [44/1000] - Train Loss: 13860.948206 - Val Loss: 17973.828544 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [45/1000] - Train Loss: 13700.563296 - Val Loss: 17866.705636 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [46/1000] - Train Loss: 13563.320240 - Val Loss: 17765.766044 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [47/1000] - Train Loss: 13427.996130 - Val Loss: 17667.914342 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [48/1000] - Train Loss: 13307.449110 - Val Loss: 17603.747349 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [49/1000] - Train Loss: 13184.218931 - Val Loss: 17514.933454 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [50/1000] - Train Loss: 13056.244321 - Val Loss: 17424.760463 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [51/1000] - Train Loss: 12939.212023 - Val Loss: 17302.052874 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [52/1000] - Train Loss: 12805.815828 - Val Loss: 17229.955497 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [53/1000] - Train Loss: 12695.047490 - Val Loss: 17170.419782 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [54/1000] - Train Loss: 12587.690249 - Val Loss: 17079.201869 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [55/1000] - Train Loss: 12480.745370 - Val Loss: 17052.028460 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [56/1000] - Train Loss: 12370.780056 - Val Loss: 17008.714565 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [57/1000] - Train Loss: 12267.565574 - Val Loss: 16915.309152 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [58/1000] - Train Loss: 12176.258174 - Val Loss: 16839.958566 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [59/1000] - Train Loss: 12048.490777 - Val Loss: 16772.661691 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [60/1000] - Train Loss: 11978.061560 - Val Loss: 16705.974330 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [61/1000] - Train Loss: 11872.572663 - Val Loss: 16619.430385 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [62/1000] - Train Loss: 11784.836769 - Val Loss: 16586.672991 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [63/1000] - Train Loss: 11678.982856 - Val Loss: 16492.582031 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [64/1000] - Train Loss: 11602.965965 - Val Loss: 16470.523019 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [65/1000] - Train Loss: 11506.720124 - Val Loss: 16406.151925 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [66/1000] - Train Loss: 11437.657878 - Val Loss: 16322.743443 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [67/1000] - Train Loss: 11349.312500 - Val Loss: 16277.831473 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [68/1000] - Train Loss: 11257.060438 - Val Loss: 16235.586775 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [69/1000] - Train Loss: 11176.922707 - Val Loss: 16209.979213 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [70/1000] - Train Loss: 11107.177156 - Val Loss: 16156.093192 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [71/1000] - Train Loss: 11030.071940 - Val Loss: 16071.669782 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [72/1000] - Train Loss: 10936.085395 - Val Loss: 16059.429269 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [73/1000] - Train Loss: 10854.919488 - Val Loss: 16006.313198 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [74/1000] - Train Loss: 10799.360460 - Val Loss: 15945.623326 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [75/1000] - Train Loss: 10721.705584 - Val Loss: 15879.825056 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [76/1000] - Train Loss: 10662.439634 - Val Loss: 15875.712891 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [77/1000] - Train Loss: 10581.480867 - Val Loss: 15816.612165 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [78/1000] - Train Loss: 10513.717484 - Val Loss: 15783.615095 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [79/1000] - Train Loss: 10449.106156 - Val Loss: 15745.717494 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [80/1000] - Train Loss: 10391.498409 - Val Loss: 15712.973493 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [81/1000] - Train Loss: 10314.002821 - Val Loss: 15692.221540 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [82/1000] - Train Loss: 10273.246600 - Val Loss: 15633.340402 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [83/1000] - Train Loss: 10177.440647 - Val Loss: 15586.737444 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [84/1000] - Train Loss: 10131.438296 - Val Loss: 15585.270229 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [85/1000] - Train Loss: 10059.154080 - Val Loss: 15502.401228 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [86/1000] - Train Loss: 9994.027271 - Val Loss: 15520.797433 - Time: 0.53s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [87/1000] - Train Loss: 9930.669416 - Val Loss: 15436.454241 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [88/1000] - Train Loss: 9882.088723 - Val Loss: 15401.422712 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [89/1000] - Train Loss: 9823.986147 - Val Loss: 15380.954241 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [90/1000] - Train Loss: 9759.383789 - Val Loss: 15360.816127 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [91/1000] - Train Loss: 9726.795609 - Val Loss: 15313.662946 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [92/1000] - Train Loss: 9663.321723 - Val Loss: 15282.259347 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [93/1000] - Train Loss: 9607.306821 - Val Loss: 15240.697266 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [94/1000] - Train Loss: 9535.328957 - Val Loss: 15207.338867 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [95/1000] - Train Loss: 9499.009476 - Val Loss: 15186.930664 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [96/1000] - Train Loss: 9433.564742 - Val Loss: 15135.067662 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [97/1000] - Train Loss: 9369.895833 - Val Loss: 15124.561663 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [98/1000] - Train Loss: 9342.309932 - Val Loss: 15089.874302 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [99/1000] - Train Loss: 9282.747577 - Val Loss: 15072.797991 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [100/1000] - Train Loss: 9230.162616 - Val Loss: 15065.148856 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [101/1000] - Train Loss: 9176.359737 - Val Loss: 14993.053432 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [102/1000] - Train Loss: 9130.428602 - Val Loss: 14992.298131 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [103/1000] - Train Loss: 9089.456742 - Val Loss: 14935.690988 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [104/1000] - Train Loss: 9026.640589 - Val Loss: 14941.105748 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [105/1000] - Train Loss: 8987.315719 - Val Loss: 14879.538504 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [106/1000] - Train Loss: 8939.817347 - Val Loss: 14898.630720 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [107/1000] - Train Loss: 8904.151403 - Val Loss: 14895.569475 - Time: 0.54s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [108/1000] - Train Loss: 8863.509838 - Val Loss: 14858.617327 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [109/1000] - Train Loss: 8797.323893 - Val Loss: 14827.054548 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [110/1000] - Train Loss: 8752.665762 - Val Loss: 14783.755441 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [111/1000] - Train Loss: 8717.587493 - Val Loss: 14792.535435 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [112/1000] - Train Loss: 8664.882125 - Val Loss: 14783.440011 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [113/1000] - Train Loss: 8629.903320 - Val Loss: 14732.916992 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [114/1000] - Train Loss: 8588.983977 - Val Loss: 14686.647740 - Time: 0.52s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [115/1000] - Train Loss: 8554.341833 - Val Loss: 14670.369280 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [116/1000] - Train Loss: 8504.766457 - Val Loss: 14650.081752 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [117/1000] - Train Loss: 8448.385525 - Val Loss: 14668.428990 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [118/1000] - Train Loss: 8421.052933 - Val Loss: 14609.901786 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [119/1000] - Train Loss: 8376.779387 - Val Loss: 14576.733817 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [120/1000] - Train Loss: 8341.413737 - Val Loss: 14570.264927 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [121/1000] - Train Loss: 8278.884494 - Val Loss: 14539.772600 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [122/1000] - Train Loss: 8262.752785 - Val Loss: 14536.177316 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [123/1000] - Train Loss: 8225.405165 - Val Loss: 14522.385184 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [124/1000] - Train Loss: 8166.994050 - Val Loss: 14486.491769 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [125/1000] - Train Loss: 8132.197465 - Val Loss: 14472.351144 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [126/1000] - Train Loss: 8078.103642 - Val Loss: 14454.252093 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [127/1000] - Train Loss: 8045.995804 - Val Loss: 14453.518136 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [128/1000] - Train Loss: 8031.272714 - Val Loss: 14420.012277 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [129/1000] - Train Loss: 7995.767795 - Val Loss: 14388.875140 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [130/1000] - Train Loss: 7948.943396 - Val Loss: 14376.438477 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [131/1000] - Train Loss: 7927.076172 - Val Loss: 14375.670619 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [132/1000] - Train Loss: 7890.498716 - Val Loss: 14362.349888 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [133/1000] - Train Loss: 7834.761646 - Val Loss: 14323.885882 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [134/1000] - Train Loss: 7799.222114 - Val Loss: 14285.369838 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [135/1000] - Train Loss: 7777.488733 - Val Loss: 14287.353376 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [136/1000] - Train Loss: 7749.574599 - Val Loss: 14256.471122 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [137/1000] - Train Loss: 7708.065032 - Val Loss: 14262.540597 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [138/1000] - Train Loss: 7667.854510 - Val Loss: 14214.871931 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [139/1000] - Train Loss: 7631.346933 - Val Loss: 14231.890346 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [140/1000] - Train Loss: 7608.245425 - Val Loss: 14185.027623 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [141/1000] - Train Loss: 7573.726020 - Val Loss: 14232.294782 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [142/1000] - Train Loss: 7540.761574 - Val Loss: 14159.938337 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [143/1000] - Train Loss: 7509.323730 - Val Loss: 14169.811523 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [144/1000] - Train Loss: 7482.192220 - Val Loss: 14146.091657 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [145/1000] - Train Loss: 7456.783854 - Val Loss: 14092.885603 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [146/1000] - Train Loss: 7411.545917 - Val Loss: 14088.210379 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [147/1000] - Train Loss: 7369.097331 - Val Loss: 14082.971401 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [148/1000] - Train Loss: 7349.219256 - Val Loss: 14120.498465 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [149/1000] - Train Loss: 7326.598416 - Val Loss: 14060.113839 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [150/1000] - Train Loss: 7286.150029 - Val Loss: 14022.096680 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [151/1000] - Train Loss: 7258.663158 - Val Loss: 14059.691685 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [152/1000] - Train Loss: 7234.034541 - Val Loss: 13997.070871 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [153/1000] - Train Loss: 7200.302517 - Val Loss: 13981.196429 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [154/1000] - Train Loss: 7173.033456 - Val Loss: 13981.775809 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [155/1000] - Train Loss: 7157.009748 - Val Loss: 13962.276367 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [156/1000] - Train Loss: 7109.452076 - Val Loss: 13954.731027 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [157/1000] - Train Loss: 7093.861491 - Val Loss: 13950.262974 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [158/1000] - Train Loss: 7055.303096 - Val Loss: 13930.547991 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [159/1000] - Train Loss: 7028.844256 - Val Loss: 13908.155971 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [160/1000] - Train Loss: 7000.403139 - Val Loss: 13898.332310 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [161/1000] - Train Loss: 6978.216616 - Val Loss: 13890.286830 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [162/1000] - Train Loss: 6945.022298 - Val Loss: 13858.154994 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [163/1000] - Train Loss: 6911.006854 - Val Loss: 13855.200335 - Time: 0.69s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [164/1000] - Train Loss: 6900.002586 - Val Loss: 13866.705497 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [165/1000] - Train Loss: 6871.533872 - Val Loss: 13802.246094 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [166/1000] - Train Loss: 6825.836353 - Val Loss: 13831.482840 - Time: 0.67s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [167/1000] - Train Loss: 6802.938513 - Val Loss: 13808.318220 - Time: 0.53s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [168/1000] - Train Loss: 6770.650861 - Val Loss: 13811.772182 - Time: 0.53s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [169/1000] - Train Loss: 6754.889775 - Val Loss: 13781.899135 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [170/1000] - Train Loss: 6719.629847 - Val Loss: 13761.750837 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [171/1000] - Train Loss: 6711.899685 - Val Loss: 13734.648298 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [172/1000] - Train Loss: 6682.143663 - Val Loss: 13729.860212 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [173/1000] - Train Loss: 6639.267144 - Val Loss: 13720.744420 - Time: 0.68s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [174/1000] - Train Loss: 6611.865650 - Val Loss: 13714.349749 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [175/1000] - Train Loss: 6589.784758 - Val Loss: 13725.457310 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [176/1000] - Train Loss: 6567.414008 - Val Loss: 13679.708845 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [177/1000] - Train Loss: 6543.681026 - Val Loss: 13666.481724 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [178/1000] - Train Loss: 6535.417806 - Val Loss: 13664.684012 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [179/1000] - Train Loss: 6512.604565 - Val Loss: 13645.157785 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [180/1000] - Train Loss: 6481.178639 - Val Loss: 13664.292550 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [181/1000] - Train Loss: 6457.420645 - Val Loss: 13641.539062 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [182/1000] - Train Loss: 6421.359086 - Val Loss: 13610.007533 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [183/1000] - Train Loss: 6413.041432 - Val Loss: 13602.217773 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [184/1000] - Train Loss: 6373.639395 - Val Loss: 13594.910714 - Time: 0.68s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [185/1000] - Train Loss: 6348.508301 - Val Loss: 13579.404715 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [186/1000] - Train Loss: 6325.011954 - Val Loss: 13562.080776 - Time: 0.61s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [187/1000] - Train Loss: 6316.473307 - Val Loss: 13557.088867 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [188/1000] - Train Loss: 6278.365650 - Val Loss: 13521.244699 - Time: 0.70s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [189/1000] - Train Loss: 6251.937536 - Val Loss: 13540.056920 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [190/1000] - Train Loss: 6254.287869 - Val Loss: 13541.987444 - Time: 0.60s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [191/1000] - Train Loss: 6228.070421 - Val Loss: 13510.154576 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [192/1000] - Train Loss: 6189.721065 - Val Loss: 13498.500000 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [193/1000] - Train Loss: 6186.767271 - Val Loss: 13465.601144 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [194/1000] - Train Loss: 6148.234610 - Val Loss: 13474.303711 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [195/1000] - Train Loss: 6137.897714 - Val Loss: 13454.189174 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [196/1000] - Train Loss: 6103.198423 - Val Loss: 13454.913923 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [197/1000] - Train Loss: 6085.230433 - Val Loss: 13456.504883 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [198/1000] - Train Loss: 6062.960847 - Val Loss: 13431.436384 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [199/1000] - Train Loss: 6040.040093 - Val Loss: 13420.485212 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [200/1000] - Train Loss: 6018.137406 - Val Loss: 13395.698940 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [201/1000] - Train Loss: 5994.917010 - Val Loss: 13406.455915 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [202/1000] - Train Loss: 5982.734321 - Val Loss: 13390.034180 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [203/1000] - Train Loss: 5950.686759 - Val Loss: 13384.961217 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [204/1000] - Train Loss: 5923.987703 - Val Loss: 13402.523996 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [205/1000] - Train Loss: 5911.966869 - Val Loss: 13370.791713 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [206/1000] - Train Loss: 5898.753888 - Val Loss: 13371.059710 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [207/1000] - Train Loss: 5879.398998 - Val Loss: 13371.096261 - Time: 0.55s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [208/1000] - Train Loss: 5854.887659 - Val Loss: 13318.194336 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [209/1000] - Train Loss: 5831.137985 - Val Loss: 13317.043108 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [210/1000] - Train Loss: 5814.516565 - Val Loss: 13322.018276 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [211/1000] - Train Loss: 5785.149269 - Val Loss: 13311.427037 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [212/1000] - Train Loss: 5781.334328 - Val Loss: 13292.925502 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [213/1000] - Train Loss: 5755.920898 - Val Loss: 13290.880441 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [214/1000] - Train Loss: 5736.575828 - Val Loss: 13303.107422 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [215/1000] - Train Loss: 5714.091309 - Val Loss: 13257.978376 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [216/1000] - Train Loss: 5695.269332 - Val Loss: 13264.742188 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [217/1000] - Train Loss: 5668.856753 - Val Loss: 13260.674944 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [218/1000] - Train Loss: 5649.250814 - Val Loss: 13239.178850 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [219/1000] - Train Loss: 5632.073676 - Val Loss: 13242.799107 - Time: 0.69s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [220/1000] - Train Loss: 5609.401982 - Val Loss: 13250.624163 - Time: 0.57s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [221/1000] - Train Loss: 5585.089844 - Val Loss: 13237.081334 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [222/1000] - Train Loss: 5569.604583 - Val Loss: 13213.312221 - Time: 0.61s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [223/1000] - Train Loss: 5550.748101 - Val Loss: 13183.201590 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [224/1000] - Train Loss: 5534.617820 - Val Loss: 13188.000698 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [225/1000] - Train Loss: 5522.886194 - Val Loss: 13192.599609 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [226/1000] - Train Loss: 5499.896087 - Val Loss: 13145.413783 - Time: 0.68s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [227/1000] - Train Loss: 5475.169072 - Val Loss: 13164.173968 - Time: 0.61s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [228/1000] - Train Loss: 5455.842719 - Val Loss: 13173.305525 - Time: 0.57s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [229/1000] - Train Loss: 5443.314218 - Val Loss: 13168.351562 - Time: 0.58s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [230/1000] - Train Loss: 5433.542028 - Val Loss: 13149.303432 - Time: 0.68s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [231/1000] - Train Loss: 5416.103570 - Val Loss: 13130.064872 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [232/1000] - Train Loss: 5393.131800 - Val Loss: 13129.419503 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [233/1000] - Train Loss: 5375.414840 - Val Loss: 13120.643276 - Time: 0.68s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [234/1000] - Train Loss: 5362.025807 - Val Loss: 13112.464146 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [235/1000] - Train Loss: 5342.444065 - Val Loss: 13109.682338 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [236/1000] - Train Loss: 5311.405400 - Val Loss: 13091.729492 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [237/1000] - Train Loss: 5306.247468 - Val Loss: 13121.170619 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [238/1000] - Train Loss: 5281.864873 - Val Loss: 13083.914342 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [239/1000] - Train Loss: 5267.448803 - Val Loss: 13068.607143 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [240/1000] - Train Loss: 5252.182943 - Val Loss: 13055.989816 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [241/1000] - Train Loss: 5222.924172 - Val Loss: 13066.308733 - Time: 0.64s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [242/1000] - Train Loss: 5216.732747 - Val Loss: 13027.386719 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [243/1000] - Train Loss: 5190.512388 - Val Loss: 13033.378348 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [244/1000] - Train Loss: 5169.982331 - Val Loss: 13063.428571 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [245/1000] - Train Loss: 5168.173919 - Val Loss: 13020.276646 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [246/1000] - Train Loss: 5159.016276 - Val Loss: 13020.043527 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [247/1000] - Train Loss: 5128.059733 - Val Loss: 12994.609794 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [248/1000] - Train Loss: 5122.466580 - Val Loss: 13026.819894 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [249/1000] - Train Loss: 5088.880552 - Val Loss: 13001.269671 - Time: 0.54s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [250/1000] - Train Loss: 5077.346354 - Val Loss: 12984.259347 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [251/1000] - Train Loss: 5066.133934 - Val Loss: 12985.240374 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [252/1000] - Train Loss: 5050.126248 - Val Loss: 12970.412249 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [253/1000] - Train Loss: 5026.854474 - Val Loss: 12972.383371 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [254/1000] - Train Loss: 5013.782823 - Val Loss: 12984.921038 - Time: 0.57s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [255/1000] - Train Loss: 5011.416413 - Val Loss: 12966.481306 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [256/1000] - Train Loss: 4990.165039 - Val Loss: 12978.727958 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [257/1000] - Train Loss: 4968.722656 - Val Loss: 12938.368443 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [258/1000] - Train Loss: 4938.544723 - Val Loss: 12933.050502 - Time: 0.73s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [259/1000] - Train Loss: 4946.636972 - Val Loss: 12939.226004 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [260/1000] - Train Loss: 4927.443142 - Val Loss: 12950.769531 - Time: 0.58s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [261/1000] - Train Loss: 4917.282552 - Val Loss: 12919.968192 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [262/1000] - Train Loss: 4896.019025 - Val Loss: 12894.722098 - Time: 0.70s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [263/1000] - Train Loss: 4884.782118 - Val Loss: 12891.397600 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [264/1000] - Train Loss: 4858.756113 - Val Loss: 12879.858677 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [265/1000] - Train Loss: 4849.112178 - Val Loss: 12866.793806 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [266/1000] - Train Loss: 4836.325557 - Val Loss: 12880.797712 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [267/1000] - Train Loss: 4801.782643 - Val Loss: 12854.121373 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [268/1000] - Train Loss: 4793.914822 - Val Loss: 12863.241071 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [269/1000] - Train Loss: 4800.200033 - Val Loss: 12857.993025 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [270/1000] - Train Loss: 4773.195855 - Val Loss: 12844.501535 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [271/1000] - Train Loss: 4749.941858 - Val Loss: 12855.879743 - Time: 0.53s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [272/1000] - Train Loss: 4756.073459 - Val Loss: 12839.852679 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [273/1000] - Train Loss: 4727.924841 - Val Loss: 12840.120675 - Time: 0.63s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [274/1000] - Train Loss: 4715.630877 - Val Loss: 12809.047433 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [275/1000] - Train Loss: 4682.926324 - Val Loss: 12822.025251 - Time: 0.53s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [276/1000] - Train Loss: 4688.575611 - Val Loss: 12790.669922 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [277/1000] - Train Loss: 4669.723850 - Val Loss: 12801.141323 - Time: 0.50s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [278/1000] - Train Loss: 4663.902633 - Val Loss: 12806.813756 - Time: 0.47s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [279/1000] - Train Loss: 4643.776638 - Val Loss: 12807.737584 - Time: 0.48s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [280/1000] - Train Loss: 4639.413647 - Val Loss: 12776.180385 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [281/1000] - Train Loss: 4611.325991 - Val Loss: 12773.932617 - Time: 0.47s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [282/1000] - Train Loss: 4599.320837 - Val Loss: 12782.668387 - Time: 0.48s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [283/1000] - Train Loss: 4597.838487 - Val Loss: 12748.334124 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [284/1000] - Train Loss: 4591.696759 - Val Loss: 12779.797015 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [285/1000] - Train Loss: 4551.011737 - Val Loss: 12737.397600 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [286/1000] - Train Loss: 4550.775156 - Val Loss: 12745.802037 - Time: 0.49s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [287/1000] - Train Loss: 4536.922870 - Val Loss: 12754.613281 - Time: 0.60s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [288/1000] - Train Loss: 4529.264359 - Val Loss: 12735.538783 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [289/1000] - Train Loss: 4506.719021 - Val Loss: 12728.062500 - Time: 0.51s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [290/1000] - Train Loss: 4491.771195 - Val Loss: 12717.072963 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [291/1000] - Train Loss: 4477.676631 - Val Loss: 12689.910993 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [292/1000] - Train Loss: 4479.841254 - Val Loss: 12684.348772 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [293/1000] - Train Loss: 4459.960901 - Val Loss: 12704.065988 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [294/1000] - Train Loss: 4436.326913 - Val Loss: 12675.316546 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [295/1000] - Train Loss: 4424.065086 - Val Loss: 12692.310826 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [296/1000] - Train Loss: 4408.813965 - Val Loss: 12669.596401 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [297/1000] - Train Loss: 4397.442745 - Val Loss: 12692.738839 - Time: 0.68s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [298/1000] - Train Loss: 4376.457357 - Val Loss: 12676.967076 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [299/1000] - Train Loss: 4383.742061 - Val Loss: 12671.883092 - Time: 0.57s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [300/1000] - Train Loss: 4368.604827 - Val Loss: 12644.185547 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [301/1000] - Train Loss: 4351.316063 - Val Loss: 12658.833426 - Time: 0.69s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [302/1000] - Train Loss: 4331.239927 - Val Loss: 12639.185547 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [303/1000] - Train Loss: 4326.831055 - Val Loss: 12663.823800 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [304/1000] - Train Loss: 4322.445530 - Val Loss: 12669.699079 - Time: 0.68s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [305/1000] - Train Loss: 4303.243191 - Val Loss: 12627.065709 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [306/1000] - Train Loss: 4281.013129 - Val Loss: 12642.012695 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [307/1000] - Train Loss: 4280.725043 - Val Loss: 12609.002790 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [308/1000] - Train Loss: 4268.505299 - Val Loss: 12602.153878 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [309/1000] - Train Loss: 4242.500154 - Val Loss: 12631.056641 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [310/1000] - Train Loss: 4249.106635 - Val Loss: 12576.976702 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [311/1000] - Train Loss: 4225.049949 - Val Loss: 12600.509626 - Time: 0.67s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [312/1000] - Train Loss: 4210.015743 - Val Loss: 12613.315290 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [313/1000] - Train Loss: 4209.704337 - Val Loss: 12587.409040 - Time: 0.55s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [314/1000] - Train Loss: 4180.256248 - Val Loss: 12601.569475 - Time: 0.53s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [315/1000] - Train Loss: 4173.055456 - Val Loss: 12589.667829 - Time: 0.62s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [316/1000] - Train Loss: 4157.377640 - Val Loss: 12580.857840 - Time: 0.55s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [317/1000] - Train Loss: 4146.014685 - Val Loss: 12598.116350 - Time: 0.58s\n",
      "⚠️ No improvement for 7 epochs.\n",
      "Epoch [318/1000] - Train Loss: 4153.564788 - Val Loss: 12530.961635 - Time: 0.69s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [319/1000] - Train Loss: 4121.135878 - Val Loss: 12562.499721 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [320/1000] - Train Loss: 4117.535428 - Val Loss: 12556.221261 - Time: 0.58s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [321/1000] - Train Loss: 4104.546124 - Val Loss: 12544.898996 - Time: 0.60s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [322/1000] - Train Loss: 4097.452655 - Val Loss: 12531.329660 - Time: 0.65s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [323/1000] - Train Loss: 4079.856011 - Val Loss: 12523.720006 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [324/1000] - Train Loss: 4076.753951 - Val Loss: 12526.073661 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [325/1000] - Train Loss: 4046.488779 - Val Loss: 12516.684431 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [326/1000] - Train Loss: 4031.422246 - Val Loss: 12515.696429 - Time: 0.66s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [327/1000] - Train Loss: 4045.657823 - Val Loss: 12485.012416 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [328/1000] - Train Loss: 4008.058928 - Val Loss: 12517.912249 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [329/1000] - Train Loss: 4003.549841 - Val Loss: 12493.407645 - Time: 0.67s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [330/1000] - Train Loss: 4005.448613 - Val Loss: 12494.061802 - Time: 0.56s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [331/1000] - Train Loss: 3986.074083 - Val Loss: 12521.695173 - Time: 0.57s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [332/1000] - Train Loss: 3989.956525 - Val Loss: 12473.665179 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [333/1000] - Train Loss: 3964.640697 - Val Loss: 12517.251674 - Time: 0.68s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [334/1000] - Train Loss: 3950.309941 - Val Loss: 12461.861607 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [335/1000] - Train Loss: 3943.219410 - Val Loss: 12491.362723 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [336/1000] - Train Loss: 3928.922038 - Val Loss: 12472.334542 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [337/1000] - Train Loss: 3930.812391 - Val Loss: 12470.164760 - Time: 0.57s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [338/1000] - Train Loss: 3915.787534 - Val Loss: 12442.430106 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [339/1000] - Train Loss: 3904.381791 - Val Loss: 12465.025530 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [340/1000] - Train Loss: 3896.497441 - Val Loss: 12438.993025 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [341/1000] - Train Loss: 3887.974736 - Val Loss: 12455.168945 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [342/1000] - Train Loss: 3860.652850 - Val Loss: 12411.937640 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [343/1000] - Train Loss: 3855.794497 - Val Loss: 12444.365374 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [344/1000] - Train Loss: 3859.017171 - Val Loss: 12421.551200 - Time: 0.68s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [345/1000] - Train Loss: 3827.908709 - Val Loss: 12394.119420 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [346/1000] - Train Loss: 3827.862549 - Val Loss: 12412.381975 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [347/1000] - Train Loss: 3821.838723 - Val Loss: 12412.176200 - Time: 0.69s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [348/1000] - Train Loss: 3796.259314 - Val Loss: 12426.838309 - Time: 0.58s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [349/1000] - Train Loss: 3802.062934 - Val Loss: 12392.947963 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [350/1000] - Train Loss: 3794.572591 - Val Loss: 12406.556780 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [351/1000] - Train Loss: 3769.899758 - Val Loss: 12387.895508 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [352/1000] - Train Loss: 3753.309046 - Val Loss: 12383.653181 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [353/1000] - Train Loss: 3754.610587 - Val Loss: 12375.589704 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [354/1000] - Train Loss: 3732.413963 - Val Loss: 12365.425781 - Time: 0.69s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [355/1000] - Train Loss: 3742.760543 - Val Loss: 12366.797294 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [356/1000] - Train Loss: 3739.967954 - Val Loss: 12361.590960 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [357/1000] - Train Loss: 3725.368887 - Val Loss: 12335.037946 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [358/1000] - Train Loss: 3698.620244 - Val Loss: 12331.989258 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [359/1000] - Train Loss: 3687.550085 - Val Loss: 12379.164900 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [360/1000] - Train Loss: 3675.163701 - Val Loss: 12350.981724 - Time: 0.55s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [361/1000] - Train Loss: 3665.724121 - Val Loss: 12341.061523 - Time: 0.53s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [362/1000] - Train Loss: 3673.847276 - Val Loss: 12330.110352 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [363/1000] - Train Loss: 3656.955304 - Val Loss: 12346.236886 - Time: 0.48s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [364/1000] - Train Loss: 3643.453188 - Val Loss: 12317.459124 - Time: 0.47s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [365/1000] - Train Loss: 3648.009901 - Val Loss: 12311.060547 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [366/1000] - Train Loss: 3622.803024 - Val Loss: 12328.340123 - Time: 0.53s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [367/1000] - Train Loss: 3616.671088 - Val Loss: 12329.354492 - Time: 0.53s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [368/1000] - Train Loss: 3607.628056 - Val Loss: 12301.509208 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [369/1000] - Train Loss: 3593.915600 - Val Loss: 12306.045619 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [370/1000] - Train Loss: 3595.655255 - Val Loss: 12331.097935 - Time: 0.53s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [371/1000] - Train Loss: 3581.704472 - Val Loss: 12304.994978 - Time: 0.53s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [372/1000] - Train Loss: 3560.233389 - Val Loss: 12292.866769 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [373/1000] - Train Loss: 3560.865822 - Val Loss: 12289.408761 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [374/1000] - Train Loss: 3535.302391 - Val Loss: 12292.060826 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [375/1000] - Train Loss: 3531.006411 - Val Loss: 12298.993443 - Time: 0.54s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [376/1000] - Train Loss: 3531.936279 - Val Loss: 12307.897461 - Time: 0.64s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [377/1000] - Train Loss: 3517.001655 - Val Loss: 12258.939174 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [378/1000] - Train Loss: 3512.887596 - Val Loss: 12281.483677 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [379/1000] - Train Loss: 3512.122486 - Val Loss: 12255.415179 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [380/1000] - Train Loss: 3481.468108 - Val Loss: 12249.406808 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [381/1000] - Train Loss: 3498.988905 - Val Loss: 12271.667271 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [382/1000] - Train Loss: 3473.856337 - Val Loss: 12240.023577 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [383/1000] - Train Loss: 3466.955530 - Val Loss: 12237.279715 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [384/1000] - Train Loss: 3456.036033 - Val Loss: 12211.945731 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [385/1000] - Train Loss: 3455.237929 - Val Loss: 12238.728237 - Time: 0.56s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [386/1000] - Train Loss: 3438.251040 - Val Loss: 12254.826311 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [387/1000] - Train Loss: 3433.574671 - Val Loss: 12214.808873 - Time: 0.53s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [388/1000] - Train Loss: 3427.661838 - Val Loss: 12249.380022 - Time: 0.53s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [389/1000] - Train Loss: 3405.033583 - Val Loss: 12217.503767 - Time: 0.53s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [390/1000] - Train Loss: 3399.416721 - Val Loss: 12217.204520 - Time: 0.63s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [391/1000] - Train Loss: 3387.412525 - Val Loss: 12214.856864 - Time: 0.53s\n",
      "⚠️ No improvement for 7 epochs.\n",
      "Epoch [392/1000] - Train Loss: 3368.043737 - Val Loss: 12212.691964 - Time: 0.53s\n",
      "⚠️ No improvement for 8 epochs.\n",
      "Epoch [393/1000] - Train Loss: 3370.005977 - Val Loss: 12201.525670 - Time: 0.63s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [394/1000] - Train Loss: 3371.200774 - Val Loss: 12206.354213 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [395/1000] - Train Loss: 3357.275779 - Val Loss: 12188.400530 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [396/1000] - Train Loss: 3356.266195 - Val Loss: 12187.840541 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [397/1000] - Train Loss: 3339.301604 - Val Loss: 12173.502930 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [398/1000] - Train Loss: 3318.460277 - Val Loss: 12161.808733 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [399/1000] - Train Loss: 3318.988073 - Val Loss: 12148.473354 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [400/1000] - Train Loss: 3322.395616 - Val Loss: 12158.102539 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [401/1000] - Train Loss: 3310.828007 - Val Loss: 12168.117885 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [402/1000] - Train Loss: 3291.273700 - Val Loss: 12156.699219 - Time: 0.54s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [403/1000] - Train Loss: 3289.335377 - Val Loss: 12149.549805 - Time: 0.53s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [404/1000] - Train Loss: 3271.324933 - Val Loss: 12162.777762 - Time: 0.63s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [405/1000] - Train Loss: 3264.705386 - Val Loss: 12156.712333 - Time: 0.54s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [406/1000] - Train Loss: 3272.460874 - Val Loss: 12181.384905 - Time: 0.53s\n",
      "⚠️ No improvement for 7 epochs.\n",
      "Epoch [407/1000] - Train Loss: 3248.622956 - Val Loss: 12153.687500 - Time: 0.54s\n",
      "⚠️ No improvement for 8 epochs.\n",
      "Epoch [408/1000] - Train Loss: 3234.582031 - Val Loss: 12137.351144 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [409/1000] - Train Loss: 3232.072428 - Val Loss: 12141.045898 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [410/1000] - Train Loss: 3216.839979 - Val Loss: 12154.122489 - Time: 0.54s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [411/1000] - Train Loss: 3221.420302 - Val Loss: 12137.542132 - Time: 0.66s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [412/1000] - Train Loss: 3227.302355 - Val Loss: 12143.974051 - Time: 0.54s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [413/1000] - Train Loss: 3207.039379 - Val Loss: 12142.619838 - Time: 0.53s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [414/1000] - Train Loss: 3199.941144 - Val Loss: 12119.378627 - Time: 0.53s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [415/1000] - Train Loss: 3196.066885 - Val Loss: 12103.521903 - Time: 0.65s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [416/1000] - Train Loss: 3186.000461 - Val Loss: 12087.461914 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [417/1000] - Train Loss: 3163.340097 - Val Loss: 12107.535575 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [418/1000] - Train Loss: 3173.506040 - Val Loss: 12105.838170 - Time: 0.65s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [419/1000] - Train Loss: 3176.139612 - Val Loss: 12113.947266 - Time: 0.58s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [420/1000] - Train Loss: 3153.243010 - Val Loss: 12126.899693 - Time: 0.56s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [421/1000] - Train Loss: 3141.097946 - Val Loss: 12099.616071 - Time: 0.56s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [422/1000] - Train Loss: 3130.124539 - Val Loss: 12080.952427 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [423/1000] - Train Loss: 3130.228326 - Val Loss: 12064.588867 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [424/1000] - Train Loss: 3131.017379 - Val Loss: 12065.858259 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [425/1000] - Train Loss: 3108.979121 - Val Loss: 12062.869699 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [426/1000] - Train Loss: 3095.638355 - Val Loss: 12065.976981 - Time: 0.70s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [427/1000] - Train Loss: 3102.393265 - Val Loss: 12075.988560 - Time: 0.59s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [428/1000] - Train Loss: 3092.319878 - Val Loss: 12077.384905 - Time: 0.58s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [429/1000] - Train Loss: 3071.606545 - Val Loss: 12080.966657 - Time: 0.66s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [430/1000] - Train Loss: 3075.759540 - Val Loss: 12074.053292 - Time: 0.54s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [431/1000] - Train Loss: 3071.634684 - Val Loss: 12062.271624 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [432/1000] - Train Loss: 3051.308286 - Val Loss: 12057.265067 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [433/1000] - Train Loss: 3040.474248 - Val Loss: 12098.566964 - Time: 0.64s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [434/1000] - Train Loss: 3038.946958 - Val Loss: 12040.824916 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [435/1000] - Train Loss: 3034.796134 - Val Loss: 12031.547573 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [436/1000] - Train Loss: 3020.946009 - Val Loss: 12039.508789 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [437/1000] - Train Loss: 3025.859827 - Val Loss: 12024.519252 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [438/1000] - Train Loss: 3012.399920 - Val Loss: 12057.784319 - Time: 0.57s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [439/1000] - Train Loss: 3001.169443 - Val Loss: 11991.298968 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [440/1000] - Train Loss: 2990.181496 - Val Loss: 12013.960798 - Time: 0.68s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [441/1000] - Train Loss: 2996.075304 - Val Loss: 12017.572684 - Time: 0.55s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [442/1000] - Train Loss: 2983.252197 - Val Loss: 12022.104911 - Time: 0.55s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [443/1000] - Train Loss: 2960.927762 - Val Loss: 12017.626814 - Time: 0.70s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [444/1000] - Train Loss: 2965.746853 - Val Loss: 12023.852539 - Time: 0.60s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [445/1000] - Train Loss: 2960.472783 - Val Loss: 12032.258092 - Time: 0.61s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [446/1000] - Train Loss: 2966.214301 - Val Loss: 12056.994420 - Time: 0.60s\n",
      "⚠️ No improvement for 7 epochs.\n",
      "Epoch [447/1000] - Train Loss: 2951.638401 - Val Loss: 12001.506836 - Time: 0.70s\n",
      "⚠️ No improvement for 8 epochs.\n",
      "Epoch [448/1000] - Train Loss: 2938.105713 - Val Loss: 12023.762695 - Time: 0.58s\n",
      "⚠️ No improvement for 9 epochs.\n",
      "Epoch [449/1000] - Train Loss: 2926.558368 - Val Loss: 11988.873047 - Time: 0.55s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [450/1000] - Train Loss: 2920.691922 - Val Loss: 11993.834821 - Time: 0.66s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [451/1000] - Train Loss: 2920.297038 - Val Loss: 12014.983817 - Time: 0.56s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [452/1000] - Train Loss: 2910.660654 - Val Loss: 11988.838728 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [453/1000] - Train Loss: 2909.929407 - Val Loss: 11978.140904 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [454/1000] - Train Loss: 2886.393564 - Val Loss: 11986.973075 - Time: 0.71s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [455/1000] - Train Loss: 2896.096318 - Val Loss: 12007.618164 - Time: 0.61s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [456/1000] - Train Loss: 2887.909523 - Val Loss: 11965.568359 - Time: 0.60s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [457/1000] - Train Loss: 2882.782281 - Val Loss: 11954.708984 - Time: 0.62s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [458/1000] - Train Loss: 2857.635001 - Val Loss: 11947.378488 - Time: 0.73s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [459/1000] - Train Loss: 2859.264685 - Val Loss: 11959.302455 - Time: 0.61s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [460/1000] - Train Loss: 2850.025978 - Val Loss: 11972.679129 - Time: 0.58s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [461/1000] - Train Loss: 2853.204020 - Val Loss: 11951.093052 - Time: 0.68s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [462/1000] - Train Loss: 2840.140833 - Val Loss: 11942.679129 - Time: 0.58s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [463/1000] - Train Loss: 2833.735469 - Val Loss: 11952.193499 - Time: 0.60s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [464/1000] - Train Loss: 2828.657670 - Val Loss: 11923.541016 - Time: 0.59s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [465/1000] - Train Loss: 2814.885733 - Val Loss: 11945.008092 - Time: 0.68s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [466/1000] - Train Loss: 2812.470794 - Val Loss: 11950.937221 - Time: 0.57s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [467/1000] - Train Loss: 2803.804742 - Val Loss: 11919.498884 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [468/1000] - Train Loss: 2798.881248 - Val Loss: 11950.923549 - Time: 0.67s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [469/1000] - Train Loss: 2796.927436 - Val Loss: 11904.763253 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [470/1000] - Train Loss: 2793.336932 - Val Loss: 11929.232143 - Time: 0.59s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [471/1000] - Train Loss: 2775.102729 - Val Loss: 11915.568359 - Time: 0.55s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [472/1000] - Train Loss: 2773.336164 - Val Loss: 11914.336496 - Time: 0.64s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [473/1000] - Train Loss: 2776.906259 - Val Loss: 11953.742885 - Time: 0.55s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [474/1000] - Train Loss: 2758.678214 - Val Loss: 11935.835100 - Time: 0.57s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [475/1000] - Train Loss: 2754.665464 - Val Loss: 11888.702288 - Time: 0.67s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [476/1000] - Train Loss: 2736.141602 - Val Loss: 11899.435547 - Time: 0.58s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [477/1000] - Train Loss: 2733.087863 - Val Loss: 11930.051897 - Time: 0.58s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [478/1000] - Train Loss: 2736.205566 - Val Loss: 11896.080357 - Time: 0.54s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [479/1000] - Train Loss: 2733.330232 - Val Loss: 11902.716797 - Time: 0.65s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [480/1000] - Train Loss: 2724.476562 - Val Loss: 11898.137835 - Time: 0.57s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [481/1000] - Train Loss: 2705.833822 - Val Loss: 11902.440430 - Time: 0.57s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [482/1000] - Train Loss: 2716.038303 - Val Loss: 11879.293108 - Time: 0.57s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [483/1000] - Train Loss: 2697.188458 - Val Loss: 11899.934431 - Time: 0.65s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [484/1000] - Train Loss: 2703.769016 - Val Loss: 11894.095703 - Time: 0.54s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [485/1000] - Train Loss: 2698.851572 - Val Loss: 11879.590402 - Time: 0.55s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [486/1000] - Train Loss: 2693.078586 - Val Loss: 11892.224191 - Time: 0.64s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [487/1000] - Train Loss: 2674.825864 - Val Loss: 11862.830915 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [488/1000] - Train Loss: 2671.945303 - Val Loss: 11850.134487 - Time: 0.56s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [489/1000] - Train Loss: 2671.359511 - Val Loss: 11904.675781 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [490/1000] - Train Loss: 2659.596987 - Val Loss: 11856.584403 - Time: 0.64s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [491/1000] - Train Loss: 2651.349546 - Val Loss: 11835.892299 - Time: 0.54s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [492/1000] - Train Loss: 2639.376953 - Val Loss: 11858.717634 - Time: 0.54s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [493/1000] - Train Loss: 2646.627025 - Val Loss: 11878.980329 - Time: 0.66s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [494/1000] - Train Loss: 2645.527633 - Val Loss: 11880.995815 - Time: 0.55s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [495/1000] - Train Loss: 2638.109465 - Val Loss: 11853.680943 - Time: 0.55s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [496/1000] - Train Loss: 2623.045546 - Val Loss: 11842.326730 - Time: 0.55s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [497/1000] - Train Loss: 2620.728344 - Val Loss: 11812.461496 - Time: 0.64s\n",
      "✅ Model improved! Saving checkpoint.\n",
      "Epoch [498/1000] - Train Loss: 2606.766936 - Val Loss: 11829.838588 - Time: 0.55s\n",
      "⚠️ No improvement for 1 epochs.\n",
      "Epoch [499/1000] - Train Loss: 2600.625280 - Val Loss: 11837.874581 - Time: 0.55s\n",
      "⚠️ No improvement for 2 epochs.\n",
      "Epoch [500/1000] - Train Loss: 2597.783312 - Val Loss: 11835.419922 - Time: 0.68s\n",
      "⚠️ No improvement for 3 epochs.\n",
      "Epoch [501/1000] - Train Loss: 2577.894965 - Val Loss: 11822.897461 - Time: 0.54s\n",
      "⚠️ No improvement for 4 epochs.\n",
      "Epoch [502/1000] - Train Loss: 2571.495009 - Val Loss: 11839.570452 - Time: 0.55s\n",
      "⚠️ No improvement for 5 epochs.\n",
      "Epoch [503/1000] - Train Loss: 2576.965205 - Val Loss: 11845.925781 - Time: 0.55s\n",
      "⚠️ No improvement for 6 epochs.\n",
      "Epoch [504/1000] - Train Loss: 2573.124096 - Val Loss: 11874.179827 - Time: 0.67s\n",
      "⚠️ No improvement for 7 epochs.\n",
      "Epoch [505/1000] - Train Loss: 2574.741844 - Val Loss: 11827.527623 - Time: 0.57s\n",
      "⚠️ No improvement for 8 epochs.\n",
      "Epoch [506/1000] - Train Loss: 2554.582981 - Val Loss: 11827.760045 - Time: 0.56s\n",
      "⚠️ No improvement for 9 epochs.\n",
      "Epoch [507/1000] - Train Loss: 2547.081353 - Val Loss: 11830.038504 - Time: 0.67s\n",
      "⚠️ No improvement for 10 epochs.\n",
      "⏹️ Early stopping triggered!\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "def train_model(model, X_train, y_train, X_test, y_test, epochs=100, batch_size=1024):\n",
    "    global best_val_loss, epochs_no_improve\n",
    "    model.train()\n",
    "\n",
    "    # Move tensors to GPU\n",
    "    X_train, y_train, X_test, y_test = X_train.to(device), y_train.to(device), X_test.to(device), y_test.to(device)\n",
    "\n",
    "    # Create Data Loaders\n",
    "    train_dataset = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "    test_dataset = torch.utils.data.TensorDataset(X_test, y_test)\n",
    "    \n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        start_time = time.time()\n",
    "        train_loss = 0.0\n",
    "\n",
    "        # Training loop\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            X_batch, y_batch = X_batch.to(device), y_batch.to(device)  # Move data to GPU\n",
    "            optimizer.zero_grad()\n",
    "            output = model(X_batch)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        # Compute average training loss\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "        \n",
    "        # Validation loss calculation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for X_val, y_val in test_loader:\n",
    "                X_val, y_val = X_val.to(device), y_val.to(device)  # Move data to GPU\n",
    "                val_output = model(X_val)\n",
    "                val_loss += criterion(val_output, y_val).item()\n",
    "        \n",
    "        avg_val_loss = val_loss / len(test_loader)\n",
    "        elapsed_time = time.time() - start_time\n",
    "\n",
    "        # Print training progress\n",
    "        print(f\"Epoch [{epoch+1}/{epochs}] - Train Loss: {avg_train_loss:.6f} - Val Loss: {avg_val_loss:.6f} - Time: {elapsed_time:.2f}s\")\n",
    "\n",
    "        # Early Stopping Logic\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            epochs_no_improve = 0\n",
    "            torch.save(model.state_dict(), \"c\")  # Save the best model\n",
    "            print(\"✅ Model improved! Saving checkpoint.\")\n",
    "        else:\n",
    "            epochs_no_improve += 1\n",
    "            print(f\"⚠️ No improvement for {epochs_no_improve} epochs.\")\n",
    "\n",
    "        if epochs_no_improve >= patience:\n",
    "            print(\"⏹️ Early stopping triggered!\")\n",
    "            break\n",
    "\n",
    "        model.train()  # Switch back to training mode\n",
    "\n",
    "# Start Training with CUDA\n",
    "train_model(model, X_train_final, y_train_final, X_test_final, y_test_final, epochs=1000, batch_size=1024)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Evaluating model for SNR -7 dB...\n",
      "🔎 Evaluating model for SNR -6 dB...\n",
      "🔎 Evaluating model for SNR -5 dB...\n",
      "🔎 Evaluating model for SNR -4 dB...\n",
      "🔎 Evaluating model for SNR -3 dB...\n",
      "🔎 Evaluating model for SNR -2 dB...\n",
      "🔎 Evaluating model for SNR -1 dB...\n",
      "🔎 Evaluating model for SNR 0 dB...\n",
      "🔎 Evaluating model for SNR 1 dB...\n",
      "🔎 Evaluating model for SNR 2 dB...\n",
      "\n",
      "📊 **Average Metrics by SNR Level:**\n",
      "SNR -7 dB: RRMSE_t = 0.4164, RRMSE_s = 0.3173, CC = 0.9016\n",
      "SNR -6 dB: RRMSE_t = 0.3468, RRMSE_s = 0.2589, CC = 0.9281\n",
      "SNR -5 dB: RRMSE_t = 0.2971, RRMSE_s = 0.2231, CC = 0.9451\n",
      "SNR -4 dB: RRMSE_t = 0.2681, RRMSE_s = 0.2191, CC = 0.9547\n",
      "SNR -3 dB: RRMSE_t = 0.2610, RRMSE_s = 0.2432, CC = 0.9583\n",
      "SNR -2 dB: RRMSE_t = 0.2728, RRMSE_s = 0.2806, CC = 0.9566\n",
      "SNR -1 dB: RRMSE_t = 0.2966, RRMSE_s = 0.3204, CC = 0.9507\n",
      "SNR 0 dB: RRMSE_t = 0.3258, RRMSE_s = 0.3566, CC = 0.9420\n",
      "SNR 1 dB: RRMSE_t = 0.3553, RRMSE_s = 0.3866, CC = 0.9317\n",
      "SNR 2 dB: RRMSE_t = 0.3821, RRMSE_s = 0.4096, CC = 0.9214\n",
      "\n",
      "📌 **Overall Average Metrics:**\n",
      "RRMSE_t = 0.3222, RRMSE_s = 0.3015, CC = 0.9390\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.signal import welch\n",
    "\n",
    "def calculate_rrmse_temporal(clean_signal, denoised_signal):\n",
    "    \"\"\"Calculate RRMSE in the temporal domain.\"\"\"\n",
    "    rrmse_t = np.sqrt(np.mean((clean_signal - denoised_signal) ** 2)) / np.sqrt(np.mean(clean_signal ** 2))\n",
    "    return rrmse_t\n",
    "\n",
    "def calculate_rrmse_spectral(clean_signal, denoised_signal, fs=256):\n",
    "    \"\"\"Calculate RRMSE in the spectral domain.\"\"\"\n",
    "    f_clean, psd_clean = welch(clean_signal, fs=fs, nperseg=256)\n",
    "    f_denoised, psd_denoised = welch(denoised_signal, fs=fs, nperseg=256)\n",
    "    rrmse_s = np.sqrt(np.mean((psd_clean - psd_denoised) ** 2)) / np.sqrt(np.mean(psd_clean ** 2))\n",
    "    return rrmse_s\n",
    "\n",
    "def calculate_correlation_coefficient(clean_signal, denoised_signal):\n",
    "    \"\"\"Calculate the Correlation Coefficient (CC) between clean and denoised signals.\"\"\"\n",
    "    cc = np.corrcoef(clean_signal, denoised_signal)[0, 1]\n",
    "    return cc\n",
    "\n",
    "# Evaluate for each SNR level\n",
    "results = {snr: {\"rrmse_t\": [], \"rrmse_s\": [], \"cc\": []} for snr in synthetic_eeg_eog.keys()}\n",
    "\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    print(f\"🔎 Evaluating model for SNR {snr} dB...\")\n",
    "    \n",
    "    # Load the trained EEGDiR model\n",
    "    model = EEGDiR().to(device)\n",
    "    model.load_state_dict(torch.load(\"c\"))\n",
    "    model.eval()\n",
    "    \n",
    "    # Get noisy and clean data for this SNR level\n",
    "    X_snr = torch.tensor(synthetic_eeg_eog[snr], dtype=torch.float32).to(device)\n",
    "    y_snr = torch.tensor(clean_eeg, dtype=torch.float32).to(device)\n",
    "    \n",
    "    # Get denoised signals\n",
    "    with torch.no_grad():\n",
    "        denoised_signals = model(X_snr).cpu().numpy()\n",
    "        clean_signals = y_snr.cpu().numpy()\n",
    "    \n",
    "    # Compute metrics for each EEG sample\n",
    "    for clean_signal, denoised_signal in zip(clean_signals, denoised_signals):\n",
    "        rrmse_t = calculate_rrmse_temporal(clean_signal, denoised_signal)\n",
    "        rrmse_s = calculate_rrmse_spectral(clean_signal, denoised_signal)\n",
    "        cc = calculate_correlation_coefficient(clean_signal, denoised_signal)\n",
    "        \n",
    "        results[snr][\"rrmse_t\"].append(rrmse_t)\n",
    "        results[snr][\"rrmse_s\"].append(rrmse_s)\n",
    "        results[snr][\"cc\"].append(cc)\n",
    "\n",
    "# Compute average metrics for each SNR level\n",
    "avg_results = {snr: {} for snr in synthetic_eeg_eog.keys()}\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    avg_results[snr][\"rrmse_t\"] = np.mean(results[snr][\"rrmse_t\"])\n",
    "    avg_results[snr][\"rrmse_s\"] = np.mean(results[snr][\"rrmse_s\"])\n",
    "    avg_results[snr][\"cc\"] = np.mean(results[snr][\"cc\"])\n",
    "\n",
    "# Compute overall average metrics across all SNR levels\n",
    "overall_avg_rrmse_t = np.mean([avg_results[snr][\"rrmse_t\"] for snr in synthetic_eeg_eog.keys()])\n",
    "overall_avg_rrmse_s = np.mean([avg_results[snr][\"rrmse_s\"] for snr in synthetic_eeg_eog.keys()])\n",
    "overall_avg_cc = np.mean([avg_results[snr][\"cc\"] for snr in synthetic_eeg_eog.keys()])\n",
    "\n",
    "# Print results\n",
    "print(\"\\n📊 **Average Metrics by SNR Level:**\")\n",
    "for snr in synthetic_eeg_eog.keys():\n",
    "    print(f\"SNR {snr} dB: RRMSE_t = {avg_results[snr]['rrmse_t']:.4f}, \"\n",
    "          f\"RRMSE_s = {avg_results[snr]['rrmse_s']:.4f}, CC = {avg_results[snr]['cc']:.4f}\")\n",
    "\n",
    "print(\"\\n📌 **Overall Average Metrics:**\")\n",
    "print(f\"RRMSE_t = {overall_avg_rrmse_t:.4f}, RRMSE_s = {overall_avg_rrmse_s:.4f}, CC = {overall_avg_cc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
