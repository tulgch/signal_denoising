{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Noisy EEG+EOG SNR Levels: dict_keys([-7, -6, -5, -4, -3, -2, -1, 0, 1, 2])\n",
      "Shape of Clean EEG Data: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -7: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -6: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -5: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -4: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -3: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -2: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR -1: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR 0: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR 1: (3400, 512)\n",
      "Shape of Noisy EEG+EOG Data at SNR 2: (3400, 512)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Define file paths (update if needed)\n",
    "linear_synthetic_eeg_eog_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/Linear_synthetic_eeg_eog.npy\"\n",
    "eeg_all_epochs_path = \"/home/tulgaa/Desktop/denoisenet/Linear_Mixing/EEG+EOG/EEG_all_epochs.npy\"\n",
    "\n",
    "# Load datasets\n",
    "linear_synthetic_data = np.load(linear_synthetic_eeg_eog_path, allow_pickle=True).item()\n",
    "eeg_clean_data = np.load(eeg_all_epochs_path)\n",
    "\n",
    "# Print dataset keys (SNR levels)\n",
    "print(\"Noisy EEG+EOG SNR Levels:\", linear_synthetic_data.keys())\n",
    "\n",
    "# Check dataset shapes\n",
    "print(\"Shape of Clean EEG Data:\", eeg_clean_data.shape)\n",
    "for snr in linear_synthetic_data.keys():\n",
    "    print(f\"Shape of Noisy EEG+EOG Data at SNR {snr}: {linear_synthetic_data[snr].shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Dataset Sizes:\n",
      "X_train (Noisy): (27200, 512)\n",
      "Y_train (Clean): (27200, 512)\n",
      "X_test  (Noisy): (6800, 512)\n",
      "Y_test  (Clean): (6800, 512)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Initialize lists to store training and testing data\n",
    "X_train, X_test, Y_train, Y_test = [], [], [], []\n",
    "\n",
    "# Loop through each SNR level and perform train-test split\n",
    "for snr in linear_synthetic_data.keys():\n",
    "    noisy_signals = linear_synthetic_data[snr]  # Noisy EEG+EOG\n",
    "    clean_signals = eeg_clean_data  # Ground truth (same for all SNRs)\n",
    "\n",
    "    # Train-test split (80% train, 20% test)\n",
    "    X_train_snr, X_test_snr, Y_train_snr, Y_test_snr = train_test_split(\n",
    "        noisy_signals, clean_signals, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # Append to lists\n",
    "    X_train.append(X_train_snr)\n",
    "    X_test.append(X_test_snr)\n",
    "    Y_train.append(Y_train_snr)\n",
    "    Y_test.append(Y_test_snr)\n",
    "\n",
    "# Convert lists to numpy arrays\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "X_test = np.concatenate(X_test, axis=0)\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "Y_test = np.concatenate(Y_test, axis=0)\n",
    "\n",
    "# Print final dataset sizes\n",
    "print(\"Final Dataset Sizes:\")\n",
    "print(\"X_train (Noisy):\", X_train.shape)\n",
    "print(\"Y_train (Clean):\", Y_train.shape)\n",
    "print(\"X_test  (Noisy):\", X_test.shape)\n",
    "print(\"Y_test  (Clean):\", Y_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResCNN1D(\n",
      "  (conv3): Conv1d(1, 64, kernel_size=(3,), stride=(1,), padding=(1,))\n",
      "  (conv5): Conv1d(1, 64, kernel_size=(5,), stride=(1,), padding=(2,))\n",
      "  (conv9): Conv1d(1, 64, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      "  (bn3): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn5): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (bn9): BatchNorm1d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU()\n",
      "  (res_conv): Conv1d(192, 64, kernel_size=(1,), stride=(1,))\n",
      "  (conv_out): Conv1d(64, 1, kernel_size=(9,), stride=(1,), padding=(4,))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Corrected 1D-ResCNN Model\n",
    "class ResCNN1D(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResCNN1D, self).__init__()\n",
    "\n",
    "        # Parallel Convolutional Layers (Different Kernel Sizes)\n",
    "        self.conv3 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv5 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=5, stride=1, padding=2)\n",
    "        self.conv9 = nn.Conv1d(in_channels=1, out_channels=64, kernel_size=9, stride=1, padding=4)\n",
    "\n",
    "        # Batch Normalization\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.bn5 = nn.BatchNorm1d(64)\n",
    "        self.bn9 = nn.BatchNorm1d(64)\n",
    "\n",
    "        # Activation Function\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Residual Connection (Merging Parallel Conv Outputs)\n",
    "        self.res_conv = nn.Conv1d(in_channels=192, out_channels=64, kernel_size=1, stride=1)\n",
    "\n",
    "        # Second Convolutional Block (Refining Features)\n",
    "        self.conv_out = nn.Conv1d(in_channels=64, out_channels=1, kernel_size=9, stride=1, padding=4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)  # Add channel dimension (Batch, 1, 512)\n",
    "\n",
    "        # Apply Parallel Convolutions\n",
    "        x3 = self.relu(self.bn3(self.conv3(x)))\n",
    "        x5 = self.relu(self.bn5(self.conv5(x)))\n",
    "        x9 = self.relu(self.bn9(self.conv9(x)))\n",
    "\n",
    "        # Concatenate Parallel Outputs\n",
    "        x = torch.cat([x3, x5, x9], dim=1)  # Shape: (Batch, 192, 512)\n",
    "\n",
    "        # Residual Connection (Merging Features)\n",
    "        x = self.res_conv(x)  # Shape: (Batch, 64, 512)\n",
    "\n",
    "        # Output Layer\n",
    "        x = self.conv_out(x)  # Shape: (Batch, 1, 512)\n",
    "        x = x.squeeze(1)  # Remove channel dimension (Back to (Batch, 512))\n",
    "        \n",
    "        return x\n",
    "\n",
    "# Initialize Model and Print Summary\n",
    "model = ResCNN1D()\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 20\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mX[idx], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mY[idx]\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Convert data to PyTorch tensors\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m train_dataset \u001b[38;5;241m=\u001b[39m EEGDataset(\u001b[43mX_train\u001b[49m, Y_train)\n\u001b[1;32m     21\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m EEGDataset(X_test, Y_test)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Create DataLoaders\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Define EEG dataset class\n",
    "class EEGDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.Y = torch.tensor(Y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.Y[idx]\n",
    "\n",
    "# Convert data to PyTorch tensors\n",
    "train_dataset = EEGDataset(X_train, Y_train)\n",
    "test_dataset = EEGDataset(X_test, Y_test)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Define model, loss function, and optimizer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = ResCNN1D().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Early stopping parameters\n",
    "patience = 5  # Stop training if validation loss does not improve for 'patience' epochs\n",
    "min_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "\n",
    "    for X_batch, Y_batch in train_loader:\n",
    "        X_batch, Y_batch = X_batch.to(device), Y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_batch)\n",
    "        loss = criterion(outputs, Y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Compute average training loss\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Validation Phase\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for X_val, Y_val in test_loader:\n",
    "            X_val, Y_val = X_val.to(device), Y_val.to(device)\n",
    "            val_outputs = model(X_val)\n",
    "            val_loss += criterion(val_outputs, Y_val).item()\n",
    "\n",
    "    # Compute average validation loss\n",
    "    val_loss /= len(test_loader)\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Train Loss: {train_loss:.6f} - Val Loss: {val_loss:.6f}\")\n",
    "\n",
    "    # Early stopping check\n",
    "    if val_loss < min_val_loss:\n",
    "        min_val_loss = val_loss\n",
    "        patience_counter = 0  # Reset counter\n",
    "        torch.save(model.state_dict(), \"1D_ResCNN_Best.pth\")  # Save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= patience:\n",
    "        print(\"Early stopping triggered! 🚀\")\n",
    "        break\n",
    "\n",
    "print(\"Training complete! Best model saved as '1D_ResCNN_Best.pth'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Load the best-trained model (with early stopping)\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1D_ResCNN_Best.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Move model to GPU if available\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from scipy.fft import fft\n",
    "import pandas as pd\n",
    "\n",
    "# Load the best-trained model (with early stopping)\n",
    "model.load_state_dict(torch.load(\"1D_ResCNN_Best.pth\"))\n",
    "model.eval()\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Storage for results per SNR\n",
    "snr_results = {}\n",
    "\n",
    "# Loop over each SNR level and compute evaluation metrics\n",
    "for snr in sorted(linear_synthetic_data.keys()):  # Ensure SNR levels are in order\n",
    "    print(f\"Evaluating SNR Level: {snr}\")\n",
    "\n",
    "    # Get noisy signals at this SNR\n",
    "    X_test_snr = linear_synthetic_data[snr]\n",
    "    Y_test_snr = eeg_clean_data  # Clean EEG remains the same\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    X_test_tensor = torch.tensor(X_test_snr, dtype=torch.float32).to(device)\n",
    "    Y_test_tensor = torch.tensor(Y_test_snr, dtype=torch.float32).to(device)\n",
    "\n",
    "    # Get model predictions\n",
    "    with torch.no_grad():\n",
    "        Y_pred_tensor = model(X_test_tensor)\n",
    "\n",
    "    # Convert tensors to numpy for evaluation\n",
    "    Y_clean = Y_test_tensor.cpu().numpy()\n",
    "    Y_denoised = Y_pred_tensor.cpu().numpy()\n",
    "\n",
    "    # Compute RRMSE_Temporal (Time Domain)\n",
    "    rrmse_t = np.linalg.norm(Y_clean - Y_denoised) / np.linalg.norm(Y_clean)\n",
    "\n",
    "    # Compute RRMSE_Spectral (Frequency Domain)\n",
    "    clean_fft = np.abs(fft(Y_clean, axis=-1))  # Compute FFT of clean EEG\n",
    "    denoised_fft = np.abs(fft(Y_denoised, axis=-1))  # Compute FFT of denoised EEG\n",
    "    rrmse_s = np.linalg.norm(clean_fft - denoised_fft) / np.linalg.norm(clean_fft)\n",
    "\n",
    "    # Compute Correlation Coefficient (CC)\n",
    "    num = np.sum((Y_clean - np.mean(Y_clean)) * (Y_denoised - np.mean(Y_denoised)))\n",
    "    den = np.sqrt(np.sum((Y_clean - np.mean(Y_clean))**2) * np.sum((Y_denoised - np.mean(Y_denoised))**2))\n",
    "    cc = num / den\n",
    "\n",
    "    # Compute T&S Metric\n",
    "    T_S = 10 * np.log10(np.sum(Y_clean**2) / np.sum((Y_clean - Y_denoised)**2))\n",
    "\n",
    "    # Store results\n",
    "    snr_results[snr] = {\n",
    "        \"RRMSE_T (Temporal)\": rrmse_t,\n",
    "        \"RRMSE_S (Spectral)\": rrmse_s,\n",
    "        \"CC (Correlation Coefficient)\": cc,\n",
    "        \"T&S Metric (dB)\": T_S\n",
    "    }\n",
    "\n",
    "    # Print results for this SNR\n",
    "    print(f\"  RRMSE_T: {rrmse_t:.4f}\")\n",
    "    print(f\"  RRMSE_S: {rrmse_s:.4f}\")\n",
    "    print(f\"  Correlation Coefficient (CC): {cc:.4f}\")\n",
    "    print(f\"  T&S Metric: {T_S:.4f} dB\\n\")\n",
    "\n",
    "# Convert results to Pandas DataFrame for easy viewing\n",
    "df_results = pd.DataFrame.from_dict(snr_results, orient=\"index\")\n",
    "df_results.index.name = \"SNR Level\"\n",
    "df_results = df_results.sort_index()  # Sort by SNR level\n",
    "\n",
    "# Compute Average RRMSE_T and RRMSE_S across all SNR levels\n",
    "avg_rrmse_t = df_results[\"RRMSE_T (Temporal)\"].mean()\n",
    "avg_rrmse_s = df_results[\"RRMSE_S (Spectral)\"].mean()\n",
    "\n",
    "# Print Final Summary\n",
    "print(\"\\n==== Final Evaluation Summary ====\")\n",
    "print(f\"Average RRMSE_T (Temporal): {avg_rrmse_t:.4f}\")\n",
    "print(f\"Average RRMSE_S (Spectral): {avg_rrmse_s:.4f}\")\n",
    "\n",
    "# Display final results as a table\n",
    "print(\"\\n==== Evaluation Results per SNR ====\")\n",
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
